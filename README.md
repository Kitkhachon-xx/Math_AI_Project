# ğŸ  Home Price Prediction Using Gradient Descent

> ğŸ“… Academic Year: 2024\
> ğŸ§‘â€ğŸ« Instructor: Assistant Professor Dr. Tinnaphop Dindam\
> ğŸ« Institution: Panyapiwat Institute of Management\
> ğŸ’» Course: Mathematics for AI 1

---

This repository presents a machine learning project designed to predict housing prices using a **Linear Regression model** optimized via **Gradient Descent**. It was developed as part of the coursework for **1321203 Mathematics for Artificial Intelligence 1** at **Panyapiwat Institute of Management**.

---

## ğŸ“Œ Project Overview

Predicting the price of a house is a fundamental problem in the real estate domain. The objective of this project is to demonstrate how **Gradient Descent** can be used to minimize the loss function of a linear regression model and produce accurate predictions for housing prices.
The following features are considered:

* House Area *(sq.m.)*
* Number of Rooms
* Land Size *(sq.wa)*
* Price per sq.m.

---

## ğŸ§© Introduction

Buying a home is one of the most significant financial decisions a person can make. With numerous factors influencing house prices (e.g., size, location, economic conditions), it is often difficult to estimate an accurate value.
This project applies **supervised learning** and the **Gradient Descent** algorithm to solve this problem by building a predictive model that can learn from historical data.

---

## ğŸ“– Related Concepts

### ğŸ”¹ Linear Regression

Models the relationship between the dependent variable *(house price)* and multiple independent variables:

```math
y = Î¸_0 + Î¸_1x_1 + Î¸_2x_2 + Î¸_3x_3 + Î¸_4x_4
```

### ğŸ”¹ Gradient Descent

An iterative optimization algorithm used to minimize the loss function by updating model parameters:

```math
Î¸_i^{new} = Î¸_i - Î± \cdot \frac{âˆ‚SSE}{âˆ‚Î¸_i}
```

### ğŸ”¹ Learning Rate (Î±)

Controls the step size during each iteration of Gradient Descent.

### ğŸ”¹ Loss Functions

* **MAE** â€“ Mean Absolute Error
* **MSE** â€“ Mean Squared Error
* **SSE** â€“ Sum of Squared Errors

### ğŸ”¹ Normalization

Scaling the dataset to a common range (0â€“1) before training to improve convergence.

---

## âš™ï¸ Methodology

1. **Data Collection**
   Housing records with relevant features were collected.
2. **Data Preprocessing**
   Applied normalization to ensure all features are on a similar scale.
3. **Model Building**
   Constructed a linear regression model and implemented Gradient Descent as the optimization technique.
4. **Parameter Optimization**
   Updated model parameters for **800 epochs**.
5. **Denormalization**
   Converted the normalized outputs back to real-world values for interpretation and evaluation.

---

## ğŸ“Š Results

After 800 iterations, the final **denormalized** linear regression equation obtained was:

```math
y = -5,992,800 + 44,393.77x_1 - 367,345x_2 - 19,659x_3 + 222.61x_4
```

**Accuracy**:

* Mean error: **0.0658%**
* Real-world testing error: **< 9%**

These results demonstrate the effectiveness of Gradient Descent in improving model performance.

---

## ğŸ§  Conclusion

This project confirms that **Gradient Descent** is a powerful and reliable optimization method when applied to linear regression problems such as house price prediction.

**âœ… Pros**

* High prediction accuracy
* Simple and interpretable model

**âš ï¸ Cons**

* Sensitive to learning rate selection
* Affected by outliers in the data

---

## ğŸ“š References

* ResearchGate
* BorntoDev
* Medium.com
* Bangkok Asset: *à¸šà¹‰à¸²à¸™à¸¡à¸·à¸­à¸ªà¸­à¸‡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥* ([https://www.bangkokassets.com](https://www.bangkokassets.com))

---

## ğŸ‘¨â€ğŸ’» Authors

* **Kritkhachon Jirawongrungreung** (6752300216)
* **Phanuphong Onlamul** (6752300305)
* **Phuriphon Hemkul** (6752300313)
